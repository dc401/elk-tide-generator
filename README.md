# Elasticsearch Detection Agent - Automated SIEM Detection Engineering

Production-ready automated detection engineering solution that converts CTI intelligence → Elasticsearch Detection Rules with comprehensive multi-level validation, TTP-aligned testing, and self-healing refinement.

## Features

- **Native Elasticsearch Format:** Detection rules in Elasticsearch Detection API format (Lucene queries + ECS fields)
- **Multi-Level Smart Refinement:** Auto-fixes rules at validation, integration test, and LLM judge stages
- **TTP Intent Validation:** Gemini-powered validation ensures test payloads match real-world attack patterns
- **End-to-End Testing:** Single-command pipeline testing with comprehensive reporting
- **Automated Testing:** 3-stage validation + integration testing with ephemeral Elasticsearch (Docker)
- **Empirical LLM Judge:** Quality evaluation based on actual SIEM test results
- **YAML-First I/O:** All rules and outputs in YAML (easier for LLMs and humans)
- **Security Hardened:** OWASP LLM Top 10 protection, input validation, output sanitization
- **GitHub-Only Infrastructure:** No persistent cloud resources required

## Architecture

```
CTI Files → Detection Agent → Elasticsearch Detection Rules (YAML)
                                        ↓
            STAGE 1: Validation (with auto-refinement)
            ├─ Lucene syntax check
            ├─ ECS field validation (1990 fields)
            ├─ Iterative field research (3 attempts)
            └─ LLM schema validator (research-backed)
                                        ↓
            STAGE 2: Integration Testing (with auto-refinement)
            ├─ Deploy to ephemeral Elasticsearch (Docker)
            ├─ Ingest TP/FN/FP/TN test payloads
            ├─ Calculate precision/recall metrics
            └─ Smart decision: Fix QUERY or TEST CASES
                                        ↓
            STAGE 3: LLM Judge (with auto-refinement)
            ├─ Empirical evaluation (actual test results)
            ├─ Quality scoring (≥0.75 threshold)
            └─ Deployment decision: APPROVE/REFINE/REJECT
                                        ↓
            STAGE 3.5: TTP Intent Validation (optional)
            ├─ Validate test payload realism
            ├─ Check command syntax & TTP alignment
            └─ Research-backed recommendations
                                        ↓
                    Staging → Human Review → Production
```

## Prerequisites

- Python 3.11+ (3.12 or 3.13 recommended)
- GCP account with Vertex AI enabled (for Gemini API)
- GitHub account (for CI/CD)
- git CLI
- gh CLI (GitHub CLI)
- gcloud CLI ([installation guide](https://cloud.google.com/sdk/docs/install))
- Docker (for integration testing with Elasticsearch)

## Quick Setup

### Option 1: Automated Bootstrap (Recommended)

```bash
#clone and navigate to project
git clone https://github.com/dc401/adk-tide-generator.git
cd adk-tide-generator

#run interactive bootstrap
chmod +x scripts/bootstrap.sh
./scripts/bootstrap.sh
```

The bootstrap script will:
1. Set up Python virtual environment
2. Install dependencies
3. Configure GCP credentials
4. Set up GitHub secrets
5. Validate the installation

### Option 2: Manual Setup

```bash
#1. create virtual environment
python3.11 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

#2. install dependencies
pip install --upgrade pip
pip install -r requirements.txt

#3. configure GCP
export GOOGLE_CLOUD_PROJECT="your-project-id"
export GOOGLE_CLOUD_LOCATION="us-central1"
gcloud auth application-default login

#4. add CTI files
mkdir -p cti_src
cp your-threat-intel.pdf cti_src/

#5. test CTI loading
python run_agent.py --test-cti

#6. generate detection rules
python run_agent.py --interactive
```

## Usage

### Interactive Mode (Local)

```bash
python run_agent.py --interactive
```

Prompts you for:
- CTI folder location
- Output directory
- GCP project ID
- Confirmation before generation

### Non-Interactive Mode (CI/CD)

```bash
python run_agent.py \
  --cti-folder cti_src \
  --output generated \
  --project YOUR_GCP_PROJECT \
  --location us-central1
```

### With Self-Healing Refinement (Default)

```bash
#refinement enabled by default (max 3 iterations per rule)
python run_agent.py --cti-folder cti_src --output generated
```

### Disable Refinement (for testing)

```bash
python run_agent.py --cti-folder cti_src --output generated --no-refinement
```

## End-to-End Testing

### Run Complete Pipeline (Recommended)

```bash
#test everything: generation → integration → TTP validation → summary
gh workflow run end-to-end-test.yml

#watch progress
gh run watch
```

See [END_TO_END_TEST.md](END_TO_END_TEST.md) for detailed usage and configuration options.

### Reuse Existing Rules

```bash
#skip generation, test existing artifacts
gh workflow run end-to-end-test.yml \
  -f skip_generation=true \
  -f existing_run_id=<RUN_ID>
```

### Quick Integration Test Only

```bash
#disable TTP validation for faster testing
gh workflow run end-to-end-test.yml \
  -f run_ttp_validator=false
```

## Validation & Testing

### Stage 1: Pre-Integration Validation

```bash
python scripts/validate_rules.py \
  --rules-dir generated/detection_rules \
  --staging-dir generated/staging \
  --project YOUR_GCP_PROJECT
```

Validates:
- Lucene syntax (deterministic)
- ECS field existence (1990 fields)
- ECS field research (3 attempts if invalid)
- YAML → JSON conversion
- LLM schema validation (research-backed)

Auto-refines up to 3 times per rule if failures occur.

### Stage 2: Integration Testing

```bash
python scripts/execute_detection_tests.py \
  --rules-dir generated/detection_rules \
  --es-url http://localhost:9200
```

Tests:
- Deploys rules to Elasticsearch (Docker container)
- Ingests TP/FN/FP/TN test payloads
- Calculates precision/recall/F1/accuracy
- Smart decision: Fix query OR test cases

Quality Thresholds:
- Precision ≥ 0.60 (max 40% false positives)
- Recall ≥ 0.70 (catch at least 70% of attacks)

### Stage 3: LLM Judge Evaluation

```bash
python scripts/run_llm_judge.py \
  --rules-dir generated/detection_rules \
  --test-results integration_test_results.yml \
  --project YOUR_GCP_PROJECT
```

Evaluates:
- Quality score based on actual test results (≥0.75 threshold)
- Deployment recommendation (APPROVE/REFINE/REJECT)
- Refines based on judge feedback if needed

### Stage 3.5: TTP Intent Validation

```bash
python scripts/test_ttp_validator.py generated/detection_rules
```

Validates:
- Command syntax realism (would it work in real attack?)
- TTP alignment (does payload match MITRE technique?)
- Field value realism (realistic log values?)
- Evasion technique validity (FN cases)

Outputs:
- Valid/invalid test case counts
- High/medium/low confidence scores
- Research-backed recommendations for invalid cases

## Multi-Level Refinement System

The system automatically refines rules at each failure stage:

### Validation Refinement
- **Trigger:** Lucene syntax errors, ECS field errors, schema violations
- **Fix:** Corrects operators, researches ECS fields, fixes MITRE references
- **Attempts:** Max 3 per rule

### Integration Test Refinement
- **Trigger:** Precision < 0.60 or Recall < 0.70
- **Smart Decision:** Analyzes if QUERY or TEST CASES need fixing
- **Fix:** Refines query logic OR updates test payloads
- **Attempts:** Max 2 per rule

### Judge Refinement
- **Trigger:** Deployment decision = REFINE
- **Fix:** Applies judge's specific recommendations
- **Attempts:** Max 2 per rule

See [docs/milestones/ITERATIVE_VALIDATION_SUCCESS.md](docs/milestones/ITERATIVE_VALIDATION_SUCCESS.md) for detailed documentation.

## Project Structure

```
adk-tide-generator/
├── detection_agent/               #core detection generation logic
│   ├── agent.py                   #main detection agent (5 stages)
│   ├── prompts/                   #LLM prompts (external files)
│   │   ├── detection_generator.md #rule generation with ECS research
│   │   ├── validator.md           #rule validation with research
│   │   ├── security_scan.md       #OWASP LLM Top 10 protection
│   │   └── ttp_validator_prompt.md #TTP intent validation guide
│   ├── schemas/                   #Pydantic schemas
│   │   ├── detection_rule.py      #ES Detection Rule schema
│   │   └── ecs_flat.yml           #1990 ECS fields
│   └── tools/                     #custom tools
│       ├── load_cti_files.py      #CTI file loader (PDF/DOCX/TXT/MD)
│       ├── validate_lucene.py     #Lucene syntax validator
│       ├── validate_ecs_fields.py #ECS field validator
│       ├── research_ecs_field.py  #ECS field research tool
│       ├── iterative_validator.py #3-attempt validation wrapper
│       └── ttp_intent_validator.py #TTP test payload validator
│
├── scripts/                       #validation and testing scripts
│   ├── bootstrap.sh               #interactive setup script
│   ├── validate_rules.py          #3-stage validation with refinement
│   ├── execute_detection_tests.py #ES integration testing
│   ├── integration_test_ci.py     #CI integration wrapper
│   ├── run_llm_judge.py           #empirical LLM judge with refinement
│   ├── test_ttp_validator.py      #TTP validator testing
│   ├── demo_ttp_validation.py     #TTP validator demonstration
│   ├── stage_passing_rules.py     #stage validated rules with UIDs
│   ├── create_review_pr.py        #automated PR creation
│   ├── deploy_local_demo.sh       #local deployment demo
│   ├── cleanup_staging.sh         #clean temp artifacts
│   ├── setup-gcp.sh               #GCP setup helper
│   └── setup-github-secrets.sh    #GitHub secrets helper
│
├── .github/workflows/             #CI/CD workflows
│   ├── end-to-end-test.yml        #master orchestration (6-12 min)
│   ├── generate-detections.yml    #rule generation (3-4 min)
│   ├── integration-test-simple.yml #integration testing (1-2 min)
│   ├── llm-judge.yml              #LLM quality evaluation
│   ├── mock-deploy.yml            #mock SIEM deployment
│   └── cleanup-stale-artifacts.yml #artifact cleanup
│
├── cti_src/                       #CTI input files
│   └── sample_cti.md              #example CTI file
│
├── generated/                     #agent outputs (gitignored)
│   ├── detection_rules/           #generated YAML rules
│   ├── cti_context.yml            #CTI analysis context
│   └── staging/                   #temp validation artifacts
│
├── production_rules/              #human-approved rules (deployed)
│   └── *.yml                      #production detection rules
│
├── archived_rules/                #deployment history
│   └── batch_*_deployed_*/        #audit trail with metadata
│
├── docs/                          #documentation
│   ├── milestones/                #important milestone documentation
│   │   ├── CORE_ECS_FIELD_FIX_SUCCESS.md
│   │   ├── ITERATIVE_VALIDATION_SUCCESS.md
│   │   ├── INTEGRATION_TEST_SUCCESS.md
│   │   ├── MOCK_DEPLOYMENT_SUCCESS.md
│   │   ├── STAGE_3_COMPLETE_PR_CREATED.md
│   │   └── TTP_VALIDATOR_IMPROVEMENT_CYCLE.md
│   └── archive/                   #session progress notes (historical)
│
├── run_agent.py                   #CLI entry point
├── requirements.txt               #Python dependencies
├── README.md                      #this file
├── END_TO_END_TEST.md             #end-to-end testing guide
├── SESSION_SUMMARY.md             #comprehensive session summary
├── BACKLOG.md                     #future improvements
├── TESTING_GUIDE.md               #testing documentation
└── ARCHITECTURE_ELASTICSEARCH_NATIVE.md #technical architecture
```

## GitHub Actions Workflows

### 1. End-to-End Test (Master Orchestration)
**File:** `.github/workflows/end-to-end-test.yml`
**Trigger:** Manual dispatch
**Runtime:** 6-12 minutes

Orchestrates complete pipeline:
1. Generate detection rules (or skip with existing run_id)
2. Integration test with ephemeral Elasticsearch
3. TTP Intent Validation (optional)
4. Aggregate results into summary report

See [END_TO_END_TEST.md](END_TO_END_TEST.md) for usage.

### 2. Generate Detection Rules
**File:** `.github/workflows/generate-detections.yml`
**Trigger:** Manual dispatch or push to main with CTI changes
**Runtime:** 3-4 minutes

Workflow steps:
1. Clean stale artifacts
2. Install dependencies
3. Authenticate to GCP
4. Check CTI files (security validation)
5. Run detection agent with refinement
6. Verify rule generation
7. Upload artifacts

### 3. Integration Test (Simple)
**File:** `.github/workflows/integration-test-simple.yml`
**Trigger:** Manual dispatch with artifact_run_id
**Runtime:** 1-2 minutes

Tests generated rules with Docker Elasticsearch.

### 4. Mock SIEM Deployment
**File:** `.github/workflows/mock-deploy.yml`
**Trigger:** PR merge to main
**Runtime:** 2-3 minutes

Demonstrates deployment to production (mock).

## Security Features

### OWASP LLM Top 10 Protection
- Scans CTI for prompt injection patterns
- Blocks jailbreak attempts
- Detects data poisoning
- Validates output for manipulation

### Input Validation
- File size limits (max 50MB per file)
- Path traversal prevention
- Allowed file extensions only (.pdf, .txt, .md, .docx)
- Suspicious filename detection
- Max 50 files per run (DoS prevention)

### Output Sanitization
- Removes injection patterns from generated rules
- Validates Lucene syntax before writing
- ECS field validation with research grounding
- Schema validation with research

## Cost Optimization

### Model Selection
- **Gemini 2.5 Flash:** Rule generation (fast, cheap, $0.000075/1K input tokens)
- **Gemini 2.5 Pro:** Validation, judging, TTP validation (accurate, $0.00125/1K input tokens)

### Quota Management
- Inter-agent delay: 3.0s
- Aggressive retry backoff
- Session-level retry with exponential backoff
- Max 3 validation iterations per rule
- Max 2 integration test iterations per rule
- Max 2 judge iterations per rule

### Token Efficiency
- External prompts (no inline repetition)
- Truncated outputs (120k char limit)
- State pruning between stages
- Field research caching

## Testing

### Unit Tests
```bash
#test CTI loading
python run_agent.py --test-cti

#test validation only
python scripts/validate_rules.py --rules-dir generated/detection_rules
```

### Integration Tests
```bash
#test with Docker Elasticsearch
docker run -d --name elasticsearch \
  -p 9200:9200 \
  -e "discovery.type=single-node" \
  -e "xpack.security.enabled=false" \
  docker.elastic.co/elasticsearch/elasticsearch:8.12.0

python scripts/execute_detection_tests.py \
  --rules-dir generated/detection_rules \
  --es-url http://localhost:9200
```

### End-to-End Test (GitHub Actions)
```bash
#complete pipeline
gh workflow run end-to-end-test.yml

#watch progress
gh run watch

#download results
gh run download <RUN_ID>
```

### TTP Validator Test
```bash
#validate test payloads for production rules
export GOOGLE_CLOUD_PROJECT=$(gcloud config get-value project)
python scripts/test_ttp_validator.py production_rules/
```

## Troubleshooting

### GCP Authentication Errors
```bash
#re-authenticate
gcloud auth application-default login

#verify project
gcloud config get-value project

#set project if not configured
export GOOGLE_CLOUD_PROJECT="your-project-id"
export GOOGLE_CLOUD_LOCATION="us-central1"
```

### Quota Exhaustion
```bash
#check quota usage
gcloud alpha services quota list \
  --service=aiplatform.googleapis.com \
  --filter="metric.type:aiplatform.googleapis.com/quota/generate_content_requests_per_minute_per_project_per_region"

#increase delay between agents (edit detection_agent/agent.py)
INTER_AGENT_DELAY = 5.0  # increase from 3.0
```

### Rule Generation Failures
```bash
#enable verbose logging
export PYTHONUNBUFFERED=1
python run_agent.py --interactive

#disable refinement for debugging
python run_agent.py --interactive --no-refinement

#check session results
cat session_results/detection_session_*.json | jq .
```

### Integration Test Failures
```bash
#check Elasticsearch status
curl http://localhost:9200/_cluster/health

#manually restart Docker container
docker restart elasticsearch

#check Elasticsearch logs
docker logs elasticsearch

#check version compatibility (must be 8.12.0)
grep "elasticsearch==" requirements.txt
```

### Elasticsearch Version Mismatch
```bash
#symptom: "Accept version must be either version 8 or 7, but found 9"
#fix: ensure requirements.txt has correct versions
elasticsearch==8.12.0
elastic-transport==8.15.1
```

### TTP Validation Errors
```bash
#check GCP authentication
gcloud auth application-default login

#verify project is set
echo $GOOGLE_CLOUD_PROJECT

#run with explicit project
python scripts/test_ttp_validator.py \
  --project YOUR_PROJECT_ID \
  generated/detection_rules/
```

## Documentation

### Essential
- [README.md](README.md) - This file
- [END_TO_END_TEST.md](END_TO_END_TEST.md) - End-to-end testing guide
- [SESSION_SUMMARY.md](SESSION_SUMMARY.md) - Comprehensive session summary
- [BACKLOG.md](BACKLOG.md) - Future improvements roadmap
- [TESTING_GUIDE.md](TESTING_GUIDE.md) - Testing procedures
- [ARCHITECTURE_ELASTICSEARCH_NATIVE.md](ARCHITECTURE_ELASTICSEARCH_NATIVE.md) - Technical architecture

### Milestones
- [docs/milestones/CORE_ECS_FIELD_FIX_SUCCESS.md](docs/milestones/CORE_ECS_FIELD_FIX_SUCCESS.md) - ECS field fix milestone
- [docs/milestones/ITERATIVE_VALIDATION_SUCCESS.md](docs/milestones/ITERATIVE_VALIDATION_SUCCESS.md) - Iterative validation system
- [docs/milestones/INTEGRATION_TEST_SUCCESS.md](docs/milestones/INTEGRATION_TEST_SUCCESS.md) - Integration testing milestone
- [docs/milestones/MOCK_DEPLOYMENT_SUCCESS.md](docs/milestones/MOCK_DEPLOYMENT_SUCCESS.md) - Mock deployment milestone
- [docs/milestones/STAGE_3_COMPLETE_PR_CREATED.md](docs/milestones/STAGE_3_COMPLETE_PR_CREATED.md) - Human-in-the-loop workflow
- [docs/milestones/TTP_VALIDATOR_IMPROVEMENT_CYCLE.md](docs/milestones/TTP_VALIDATOR_IMPROVEMENT_CYCLE.md) - TTP validator demonstration

## Quality Metrics

### Current Production Rules
- **Rules Deployed:** 3 (Akira ransomware detection set)
- **LLM Quality Scores:** 0.93-0.97 (all pass ≥0.75 threshold)
- **Integration Test Precision:** 45.5%
- **Integration Test Recall:** 62.5%
- **TTP Validation Pass Rate:** 88% (15/17 valid initial, 100% after fixes)

### Target Metrics
- **Precision:** ≥ 0.60 (max 40% false positives)
- **Recall:** ≥ 0.70 (catch at least 70% of attacks)
- **LLM Quality Score:** ≥ 0.75
- **TTP Validation:** 100% valid test cases

See [BACKLOG.md](BACKLOG.md) for planned quality improvements.

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly:
   - Unit tests
   - Integration tests
   - End-to-end workflow test
5. Update documentation
6. Submit a pull request

## License

MIT License - See LICENSE file for details

## Support

For issues and questions:
- GitHub Issues: https://github.com/dc401/adk-tide-generator/issues
- Documentation: See docs/ folder
- Session Summary: [SESSION_SUMMARY.md](SESSION_SUMMARY.md)

## Acknowledgments

Built with:
- Google Gemini 2.5 (Flash & Pro) via Vertex AI
- Elasticsearch Detection Rule API (8.12.0)
- ECS (Elastic Common Schema) 8.11
- luqum (Lucene query parser)
- Pydantic (schema validation)
- GitHub Actions (CI/CD)
- Docker (ephemeral testing infrastructure)
