name: Generate Detection Rules from CTI

#generate Sigma rules and test payloads from CTI sources
#runs agent in GitHub Actions environment

on:
  workflow_dispatch:  #manual trigger
  push:
    branches: [main]
    paths:
      - 'cti_src/**'  #trigger when CTI files change
  schedule:
    - cron: '0 0 * * 0'  #weekly on Sunday

permissions:
  contents: write  #allow workflow to commit and push

jobs:
  generate-rules:
    name: Generate Sigma Rules from CTI
    runs-on: ubuntu-latest
    timeout-minutes: 60  #increased for larger CTI files with more indicators

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Clean Stale Artifacts
        run: |
          echo "Cleaning stale artifacts from previous runs..."

          #run cleanup script
          bash scripts/cleanup_staging.sh

          #clean local session_results folder (not committed but may exist from manual runs)
          rm -rf session_results/*
          echo "✓ Cleaned session_results/"

          echo "Ready for fresh generation run"

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          echo "Installing Python dependencies..."
          pip install --upgrade pip
          pip install -r requirements.txt
          echo "✓ Dependencies installed successfully"

      - name: Authenticate to GCP
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Check CTI Files
        run: |
          echo "Validating CTI files..."

          #check for valid file extensions only
          CTI_FILES=$(find cti_src -type f \( -name "*.md" -o -name "*.txt" -o -name "*.pdf" -o -name "*.docx" \))
          FILE_COUNT=$(echo "$CTI_FILES" | grep -c . || echo 0)

          echo "Found $FILE_COUNT CTI file(s)"

          #validation checks
          if [ "$FILE_COUNT" -eq 0 ]; then
            echo "ERROR: No CTI files found in cti_src/"
            exit 1
          fi

          #prevent DoS from too many files (max 50 files)
          if [ "$FILE_COUNT" -gt 50 ]; then
            echo "ERROR: Too many CTI files ($FILE_COUNT > 50)"
            echo "Process files in batches to avoid quota exhaustion"
            exit 1
          fi

          #check for suspicious file names
          SUSPICIOUS_FILES=$(find cti_src -type f -name "*../*" -o -name "*.exe" -o -name "*.sh" -o -name "*.bat")
          if [ -n "$SUSPICIOUS_FILES" ]; then
            echo "ERROR: Suspicious files detected:"
            echo "$SUSPICIOUS_FILES"
            exit 1
          fi

          #check for overly large files (>50MB per file)
          LARGE_FILES=$(find cti_src -type f -size +50M)
          if [ -n "$LARGE_FILES" ]; then
            echo "ERROR: Files exceed 50MB size limit:"
            echo "$LARGE_FILES"
            exit 1
          fi

          echo "✓ All CTI files validated"
          echo "CTI files to process:"
          echo "$CTI_FILES" | while read -r file; do
            SIZE=$(du -h "$file" | cut -f1)
            echo "  - $file ($SIZE)"
          done

      - name: Generate Detection Rules
        env:
          GOOGLE_CLOUD_PROJECT: ${{ secrets.GCP_PROJECT_ID }}
          GOOGLE_CLOUD_LOCATION: ${{ secrets.GOOGLE_CLOUD_LOCATION }}
          GOOGLE_GENAI_USE_VERTEXAI: 'true'
        run: |
          echo "Starting detection rule generation from CTI sources..."

          #use iterative mode for best quality
          python run_agent.py \
            --iterative \
            --cti-folder cti_src \
            --output generated \
            --max-retries 3

      - name: Verify Generated Rules
        run: |
          echo "Checking generated artifacts..."

          #count sigma rules
          if [ -d "generated/sigma_rules" ]; then
            RULE_COUNT=$(find generated/sigma_rules -name "*.yml" | wc -l)
            echo "Generated Sigma rules: $RULE_COUNT"
            ls -lh generated/sigma_rules/
          else
            echo "WARNING: No sigma_rules directory found"
            RULE_COUNT=0
          fi

          #count test payloads
          if [ -d "generated/tests" ]; then
            TEST_COUNT=$(find generated/tests -name "*.json" | wc -l)
            echo "Generated test payloads: $TEST_COUNT"
            ls -lh generated/tests/
          else
            echo "WARNING: No tests directory found"
            TEST_COUNT=0
          fi

          #require at least some output
          if [ "$RULE_COUNT" -eq 0 ]; then
            echo "ERROR: No Sigma rules were generated"
            exit 1
          fi

      - name: Static LLM Judge Pre-Filter
        env:
          GOOGLE_CLOUD_PROJECT: ${{ secrets.GCP_PROJECT_ID }}
          GOOGLE_CLOUD_LOCATION: ${{ secrets.GOOGLE_CLOUD_LOCATION }}
        run: |
          echo "Running static quality evaluation..."

          #backup all generated rules
          mkdir -p generated/all_rules_backup
          cp -r generated/sigma_rules/* generated/all_rules_backup/ 2>/dev/null || true
          cp -r generated/tests/* generated/all_rules_backup/ 2>/dev/null || true

          #run static LLM judge
          python scripts/static_llm_judge.py \
            --rules generated/sigma_rules \
            --tests generated/tests \
            --output generated/STATIC_QUALITY_REPORT.json \
            --filter-output generated/sigma_rules_filtered \
            --threshold 0.65 \
            --project ${{ secrets.GCP_PROJECT_ID }} \
            --location ${{ secrets.GOOGLE_CLOUD_LOCATION }}

      - name: Filter Passing Rules
        id: filter
        run: |
          #check if any rules passed
          if [ ! -d "generated/sigma_rules_filtered" ] || [ -z "$(ls -A generated/sigma_rules_filtered 2>/dev/null)" ]; then
            echo "⚠️  No rules passed static quality threshold"
            echo "All rules rejected by LLM judge"
            echo "passing_count=0" >> $GITHUB_OUTPUT
            exit 0
          fi

          #replace sigma_rules with filtered version
          rm -rf generated/sigma_rules
          mv generated/sigma_rules_filtered generated/sigma_rules

          PASSING_COUNT=$(find generated/sigma_rules -name "*.yml" 2>/dev/null | wc -l)
          echo "✅ $PASSING_COUNT rules passed static quality gate"
          echo "passing_count=$PASSING_COUNT" >> $GITHUB_OUTPUT

          #filter tests to match passing rules only
          if [ -f "generated/PASSING_RULE_IDS.json" ]; then
            echo "Filtering test payloads for passing rules..."
            python3 scripts/filter_test_payloads.py
          fi

          #cleanup backup folder (no longer needed)
          rm -rf generated/all_rules_backup
          echo "✓ Cleaned up rejected rules backup"

      - name: Commit Passing Rules
        if: steps.filter.outputs.passing_count > 0
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          #commit passing rules + quality report
          git add generated/sigma_rules/

          #add tests only if directory exists
          if [ -d "generated/tests" ]; then
            git add generated/tests/
            echo "✓ Added test payloads"
          else
            echo "⚠️  No test payloads to commit (tests directory not generated)"
          fi

          git add generated/STATIC_QUALITY_REPORT.json 2>/dev/null || true
          git add generated/PASSING_RULE_IDS.json 2>/dev/null || true

          #check if there are changes
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            PASSING_COUNT="${{ steps.filter.outputs.passing_count }}"
            TEST_COUNT=$(find generated/tests -name "*.json" 2>/dev/null | wc -l || echo 0)

            git commit -m "ci: $PASSING_COUNT rules passed static LLM judge (threshold 0.65) [skip ci]"
            git push
          fi

      - name: Upload Session Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: generation-session-results
          path: generated/iterative_session_*.json
          retention-days: 30

      - name: Summary
        if: success()
        run: |
          echo "================================"
          echo "✓ Detection Generation Complete"
          echo "================================"
          echo ""
          echo "Next steps:"
          echo "  1. Integration tests will run automatically"
          echo "  2. LLM judge will evaluate quality"
          echo "  3. Review results in PR or workflow artifacts"
          echo ""
          echo "Generated artifacts committed to generated/"
